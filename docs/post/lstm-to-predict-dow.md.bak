---
title: 'Machine Learning on Financial Time Series'
date: 2020-10-09T10:49:00.000-05:00
draft: true
tags: [R]
---

<!--
https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424

https://www.linkedin.com/pulse/how-use-machine-learning-time-series-forecasting-vegard-flovik-phd-1f/
-->

This post started as a replication of an article I read. The article used python and I thought it would be fun to replicate in R. But I found a lot of problems with the analysis as I worked through the replication. I don't want to publicly tear down another person's work, so this post will generally focus on common errors I see when people do analysis--specifically machine learning--on time series.

Financial time series are notoriously noisy, with a small signal-to-noise ratio. This makes it harder to evaluate whether your machine learning model is fitting the noise or the signal. Therefore, machine learning models on financial time series often do not do as well as simpler models.
<a href="https://www.amazon.com/Deep-Learning-R-Francois-Chollet/dp/161729554X/ref=as_li_ss_il?dchild=1&keywords=deep+learning+with+r+keras&qid=1602336565&s=books&sr=1-3&linkCode=li3&tag=fosstrading-20&linkId=7922511986776b5f147ee822425a5741&language=en_US" target="_blank"><img border="0" src="//ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=161729554X&Format=_SL250_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=fosstrading-20&language=en_US" align="right" hspace=30 vspace=10></a><img src="https://ir-na.amazon-adsystem.com/e/ir?t=fosstrading-20&language=en_US&l=li3&o=1&a=161729554X" width="1" height="1" border="0" alt="Deep Learning with R by Francois Chollet and JJ Allaire" style="border:none !important; margin:0px !important;"/>

I'd like to mention [Deep Learning in R by Francois Chollet and JJ Allaire](https://amzn.to/30SzIG8) because it does a great job emphasizing that you need to evaluate your super-cool machine learning model against simpler models.

In addition to performing better, it's easier to explain how changes in the inputs change the predictions of simpler models. Machine learning models are more like a black box. It's very hard to explain how changes in the inputs change the predictions they make.

Time series data usually has several characteristics that can bias model predictions, including [autocorrelation](https://en.wikipedia.org/wiki/Autocorrelation), non-[stationarity](https://en.wikipedia.org/wiki/Stationary_process), [seasonality](https://en.wikipedia.org/wiki/Seasonality), [time-varying](https://en.wikipedia.org/wiki/Volatility_(finance)) and [clustered volatility](https://en.wikipedia.org/wiki/Volatility_clustering). These characteristics in the data will cause problems for simple models and machine learning models. So you need to account for them to avoid biasing your predictions.

Always plot your data before estimating any model. Sometimes it's easier to spot issues with your data visually. At minimum, plots can give you some indication of what type(s) of statistical tests you should perform.

Last, but not least, you have to be very careful to avoid look-ahead bias in your data when building time series models. Look-ahead bias is when you use data you would not have at the time you need to make a prediction. We'll cover some very subtle look-ahead issues in this post.

<!--
TODO: Do you need a lot of data for machine learning models on financial time series?

I'm not going to describe how neural networks and LSTM models work in this post. The medium article gives a high-level overview of neural networks, and touches on how LSTM models work.

I'm going to use the [quantmod](https://cran.r-project.org/package=quantmod) package to pull the data from [Yahoo Finance](https://finance.yahoo.com), and the [xts](https://cran.r-project.org/package=xts) package for data manipulation.
-->


### Autocorrelation

[Durbin-Watson](https://en.wikipedia.org/wiki/Durbin-Watson_statistic)

```r
close_prices <- Cl(dji)
returns <- ROC(close_prices)

acf(close_prices)
acf(na.omit(returns))

pacf(close_prices)
pacf(na.omit(returns))
```

### Non-stationary

means 'unit-root' (trend), or that the mean and/or variance change over time.

```r
plot(close_prices, subset="/2019")
addSeries(runSD(close_prices, 120), on = NA)
tseries::adf.test(close_prices)

returns <- ROC(close_prices)

# mean is stationary, but variance is not
# ADF test doesn't catch the changing variance -> low statistical power
plot(returns, subset="/2019")
addSeries(runSD(returns, 120), on = NA)
tseries::adf.test(returns)
```

[Augmented Dickey-Fuller](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test)


This test has low statistical power, meaning it often cannot distinguish between true unit-root processes and near-unit-root processes.


<!--
Before we get started, I have few concerns with this analysis. First, it uses _prices_. This is often a problem because the series is not [*stationary*](https://en.wikipedia.org/wiki/Stationary_process). Basically, that means it has a trend, which means the distribution changes over time. Statistical analysis almost always requires a constant distribution, otherwise your estimates will be biased. This is also true for neural networks.

Now, the original analysis does [*standardize*](https://en.wikipedia.org/wiki/Standard_score).the features. That's standard practice to make the distribution roughly the same over time. But they use the entire training data set to standardize each observation. This introduces look-ahead bias. At time (t), you do not know the values for observations at time (t+1, t+2, ..., t+n). Using those future values to standardize the observation at time (t) means you're using data you don't have at time (t) to calculate the standardized value at time (t).

Also doesn't standardize for changes in volatility, which is very common in financial time series.


We will try to correct these issues in the next post.


### Replication

Now on to the code!

First, we need to download the data set. We can do this with the quantmod function `getSymbols()`. It pulls the data from Yahoo Finance and returns an xts object by default. Then we'll look at the first few observations, and plot the data.

TODO: Should I use tiingo data here? Yahoo Finance data isn't that good, and it would be a nice plug for tiingo.


```r
options(getSymbols.warning4.0 = FALSE)
library(quantmod)

dji <- getSymbols("^DJI", from = "2000-01-01", to = "2020-05-28", auto.assign = FALSE)
head(dji)
##            DJI.Open DJI.High  DJI.Low DJI.Close DJI.Volume DJI.Adjusted
## 2000-01-03 11501.85 11522.01 11305.69  11357.51  169750000     11357.51
## 2000-01-04 11349.75 11350.06 10986.45  10997.93  178420000     10997.93
## 2000-01-05 10989.37 11215.10 10938.67  11122.65  203190000     11122.65
## 2000-01-06 11113.37 11313.45 11098.45  11253.26  176550000     11253.26
## 2000-01-07 11247.06 11528.14 11239.92  11522.56  184900000     11522.56
## 2000-01-10 11532.48 11638.28 11532.48  11572.20  168180000     11572.20
str(dji)
## An 'xts' object on 2000-01-03/2020-05-27 containing:
##   Data: num [1:5132, 1:6] 11502 11350 10989 11113 11247 ...
##  - attr(*, "dimnames")=List of 2
##   ..$ : NULL
##   ..$ : chr [1:6] "DJI.Open" "DJI.High" "DJI.Low" "DJI.Close" ...
##   Indexed by objects of class: [Date] TZ: UTC
##   xts Attributes:  
## List of 2
##  $ src    : chr "yahoo"
##  $ updated: POSIXct[1:1], format: "2020-10-10 08:35:10"
chart_Series(dji)
```

![plot of chunk import-data](images/import-data-1.png)

We set `from = "2000-01-01"` and `to = "2020-05-27"` to match the time frame in the original article. And we set `auto.assign = FALSE` in the `getSymbols()` call to make `getSymbols()` return the data like most functions do. By default, `getSymbols()` creates automatically an object in your workspace, like the `load()` function does.

The `head()` function returns the first 6 observations, and the `str()` function shows you the *str*ucture of the data object. Then we use the `chart_Series()` function to plot the data.

### Creating features

Next, the original article creates 2 new features (independent variables in statistics-speak). I'll use the same variable names, to keep this analysis the same as the original.


```r
A <- dji
A$h_o <- (Hi(A) - Cl(A)) / Cl(A) * 100
A$pct_chng <- (Cl(A) - Op(A)) / Op(A) * 100
df <- A[, c("DJI.Close", "h_o", "pct_chng", "DJI.Volume")]
```

### Train / test split


```r
tr_data <- ceiling(nrow(df) * 0.8)

# the first tr_data observations are the training set
train <- df[seq_len(tr_data),]

# remove the first tr_data observations to get the test set
test <- df[-seq_len(tr_data),]

str(train)
## An 'xts' object on 2000-01-03/2016-04-28 containing:
##   Data: num [1:4106, 1:4] 11358 10998 11123 11253 11523 ...
##  - attr(*, "dimnames")=List of 2
##   ..$ : NULL
##   ..$ : chr [1:4] "DJI.Close" "h_o" "pct_chng" "DJI.Volume"
##   Indexed by objects of class: [Date] TZ: UTC
##   xts Attributes:  
## List of 2
##  $ src    : chr "yahoo"
##  $ updated: POSIXct[1:1], format: "2020-10-10 08:35:10"
str(test)
## An 'xts' object on 2016-04-29/2020-05-27 containing:
##   Data: num [1:1026, 1:4] 17774 17891 17751 17651 17661 ...
##  - attr(*, "dimnames")=List of 2
##   ..$ : NULL
##   ..$ : chr [1:4] "DJI.Close" "h_o" "pct_chng" "DJI.Volume"
##   Indexed by objects of class: [Date] TZ: UTC
##   xts Attributes:  
## List of 2
##  $ src    : chr "yahoo"
##  $ updated: POSIXct[1:1], format: "2020-10-10 08:35:10"
```

### Standardization

Observations must be in the range of the activation function.
In this case, the activation function is XYZ and the values need to be between 0 and 1.



```r
min_max_scaler <- function(x, min. = NULL, max. = NULL)
{
  # based on https://stackoverflow.com/a/47051133/271616
  # calculate min
  if (is.null(min.)) {
    min. <- min(x)
  }
  if (is.null(max.)) {
    max. <- max(x)
  }
  return((x - min.) / (max. - min.))
}

training_data <- apply(train, 2, min_max_scaler)
training_data <- xts(training_data, index(train))
head(training_data)
##            DJI.Close         h_o  pct_chng DJI.Volume
## 2000-01-03 0.4088670 0.142999558 0.3488098  0.2210046
## 2000-01-04 0.3783044 0.316114090 0.2502389  0.2328808
## 2000-01-05 0.3889051 0.082062901 0.4806596  0.2668110
## 2000-01-06 0.4000063 0.052808156 0.4831142  0.2303193
## 2000-01-07 0.4228955 0.004781269 0.5467368  0.2417572
## 2000-01-10 0.4271147 0.056377592 0.4342618  0.2188540
```

### Data preparation


```r
n_lag <- 60
x_train <- array(0.0, dim = c(nrow(training_data)-n_lag+1, n_lag, ncol(training_data)))
for (i in seq(n_lag, nrow(training_data))) {
  x_train[(i-n_lag+1),,] <- training_data[(i-60+1):i,]
}

y_train <- training_data[n_lag:nrow(training_data),1]
```

Mention pre-allocation for `x_train`. Also mention that R uses 1-based indexing while python uses 0-based indexing.
-->


<!--

```r
library(keras)
## Error: package or namespace load failed for 'keras':
##  package 'base64enc' was installed before R 4.0.0: please re-install it

model <- keras_model_sequential()
## Error in keras_model_sequential(): could not find function "keras_model_sequential"
model <- layer_lstm(model,
                    units = 10,
                    activation = 'relu',
                    return_sequences = TRUE,
                    input_shape = c(60, 4))
## Error in layer_lstm(model, units = 10, activation = "relu", return_sequences = TRUE, : could not find function "layer_lstm"
model <- layer_dropout(model, 0.1)
## Error in layer_dropout(model, 0.1): could not find function "layer_dropout"

model <- layer_lstm(model,
                    units = 20,
                    activation = 'relu',
                    return_sequences = TRUE)
## Error in layer_lstm(model, units = 20, activation = "relu", return_sequences = TRUE): could not find function "layer_lstm"
model <- layer_dropout(model, 0.2)
## Error in layer_dropout(model, 0.2): could not find function "layer_dropout"

model <- layer_lstm(model,
                    units = 30,
                    activation = 'relu')
## Error in layer_lstm(model, units = 30, activation = "relu"): could not find function "layer_lstm"
model <- layer_dropout(model, 0.3)
## Error in layer_dropout(model, 0.3): could not find function "layer_dropout"

model <- layer_dense(model, units = 1)
## Error in layer_dense(model, units = 1): could not find function "layer_dense"
```

A thing.


```r
model <- compile(model, optimizer = "adam", loss = "mean_squared_error")
## Error in compile(model, optimizer = "adam", loss = "mean_squared_error"): could not find function "compile"

num_epochs <- 10
batch_size <- 32

h1 <- fit(model,
          x = x_train,
          y = y_train,
          epochs = num_epochs,
          batch_size = batch_size,
          verbose = 1)
## Error in fit(model, x = x_train, y = y_train, epochs = num_epochs, batch_size = batch_size, : could not find function "fit"

last_60_days <- tail(train, 60)
df <- rbind(last_60_days, test)

input <- df
for (j in seq_len(ncol(input))) {
  min. <- min(train[,j])
  max. <- max(train[,j])
  input[,j] <- min_max_scaler(df[,j], min. = min., max. = max.)
}
head(input, 3)
##            DJI.Close        h_o  pct_chng DJI.Volume
## 2016-02-03 0.8320720 0.02721405 0.4655255  0.1828144
## 2016-02-04 0.8388648 0.04165338 0.4442961  0.1685958
## 2016-02-05 0.8208789 0.13322179 0.3465493  0.1788968
tail(input, 3)
##            DJI.Close         h_o  pct_chng DJI.Volume
## 2020-05-22  1.522957 0.006650793 0.4165543  0.3386847
## 2020-05-26  1.568000 0.071617629 0.4618405  0.5697985
## 2020-05-27  1.615017 0.001271805 0.4685822  0.5517855
```

Blah, blah, blah.

{enter Latin here}


```r
x_test <- array(0.0, dim = c(nrow(input)-n_lag, n_lag, ncol(input)))
for (i in seq(n_lag+1, nrow(input))) {
  x_test[(i-n_lag),,] <- input[(i-60+1):i,]
}

y_test <- input[(n_lag+1):nrow(input),1]
y_pred <- predict(model, x_test, verbose = 1)
## Error in predict(model, x_test, verbose = 1): object 'model' not found

y_pred_scaled <- y_pred * (max(train[,1])-min(train[,1])) + min(train[,1])
## Error in eval(expr, envir, enclos): object 'y_pred' not found
y_pred_scaled <- xts(y_pred_scaled, index(y_test))
## Error in xts(y_pred_scaled, index(y_test)): object 'y_pred_scaled' not found

y_test_scaled <- y_test * (max(train[,1])-min(train[,1])) + min(train[,1])
y_test_scaled <- xts(y_test_scaled, index(y_test))

foo <- merge(y_pred_scaled, y_test_scaled)
## Error in merge(y_pred_scaled, y_test_scaled): object 'y_pred_scaled' not found
p1 <- plot(foo)
## Error in plot(foo): object 'foo' not found
p1 <- addLegend("topleft", lty = 1)
## Error in get(".xts_chob", .plotxtsEnv): object '.xts_chob' not found
plot(p1)
## Error in plot(p1): object 'p1' not found

y_test_xts <- xts(y_test, index(input)[-(1:60)])
y_pred_xts <- xts(y_pred, index(input)[-(1:60)])
## Error in xts(y_pred, index(input)[-(1:60)]): object 'y_pred' not found

bar <- merge(y_pred_xts, y_test_xts)
## Error in merge(y_pred_xts, y_test_xts): object 'y_pred_xts' not found
p2 <- plot(bar)
## Error in plot(bar): object 'bar' not found
p2 <- addLegend("topleft", lty = 1)
## Error in get(".xts_chob", .plotxtsEnv): object '.xts_chob' not found
plot(p2)
## Error in plot(p2): object 'p2' not found


rmse <- function(actual, predicted)
{
  mu <- mean((predicted - actual)^2, na.rm = TRUE)
  sqrt(mu)
}

## So smart! "S. M. R. T."
# R> rmse(y_test_scaled, y_pred_scaled)
# [1] 1978.659
# R> rmse(y_test_scaled, SMA(y_test_scaled, 60))
# [1] 1185.24
# R> rmse(y_test_scaled, lag(y_test_scaled))
# [1] 300.5368

```
This is so bad. It does nearly everything wrong. It also appears to include today's data when predicting today's closing price.

I don't want to write something so negative about this post. Instead, I could turn this into a post about best practices in ML, or common mistakes when doing ML on time series.
-->

----

If you love using my open-source work (e.g. [quantmod](https://cran.r-project.org/package=quantmod), [TTR](https://cran.r-project.org/package=TTR), [IBrokers](https://cran.r-project.org/package=IBrokers), [microbenchmark](https://cran.r-project.org/package=microbenchmark) etc.), you can give back by [sponsoring me on GitHub](https://github.com/sponsors/joshuaulrich/). I truly appreciate anything you're willing and able to give!
