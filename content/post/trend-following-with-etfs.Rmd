---
title: 'Trend Following with ETFs'
date: 2022-12-19T09:49:00.000-05:00
draft: true
tags : [R]
---

This post uses R to replicate Dean Markwick's post [Trend Following with ETFs](https://dm13450.github.io/2022/11/18/Trend-Following-with-ETFs.html), which uses Julia. His post uses the 100-day moving average of stock, bond, and gold ETFs to create a trend following portfolio. Then it evaluates the impact of transaction costs and slippage.

<!--more-->

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  collapse=TRUE,
  fig.path="images/",
  fig.width=10
)
library <- function(package) {
  package <- deparse(substitute(package))
  suppressPackageStartupMessages({
    base::library(package, character.only = TRUE)
  })
}
```

### Importing the data

The first step is to import the data for the SPY, BND, and GLD ETFs. We set `adjust = TRUE` in the `getSymbols()` call so we can use the adjusted close price to calculate returns. This is important because we need the daily returns to account for any splits or dividends. These ETFs don't have splits or dividends, but it's important to set this option in case you use a security that does.

```{r, import}
library(quantmod)
setDefaults("getSymbols.tiingo", api.key = "fee64261138c2f3b44509aa620dd6ac674431968")

spy <- getSymbols("SPY", from = "2012-01-01", adjust = TRUE, src = "tiingo", auto.assign = FALSE)
bnd <- getSymbols("BND", from = "2012-01-01", adjust = TRUE, src = "tiingo", auto.assign = FALSE)
gld <- getSymbols("GLD", from = "2012-01-01", adjust = TRUE, src = "tiingo", auto.assign = FALSE)
```

### Data visualization

Visualizing the data should always be the very next step after you import data. Dean plots the prices and notes that the amount of movement (i.e. volatility) in the ETF prices are very different. This is easier to see if you look at the returns instead of the prices.

```{r, visualize}
# extract the close prices from the 'spy', 'bnd', and 'gld' objects
prices <- Cl(merge(spy, bnd, gld))

# calculate log returns
returns <- ROC(adj_close_prices, type = "discrete")

# plot prices
plot(prices, multi.panel = TRUE)

# plot returns
plot(returns, multi.panel = TRUE)
```

### Volatility scaling

```{r, volatility-scaling}
N <- 256
vol_scale <- 0.1

# calculate volatility-scaled returns
scaled_returns <- vol_scale * na.omit(returns / rollapply(returns, N, sd))
```

Next Dean divides the returns by `r N`-day volatility and multiplies them by `r 100*vol_scale`%. This is referred to as 'volatility scaling' and gives each series roughly the same volatility (`r 100*vol_scale`% in this case). This scaling is one way to adjust position size to create an equal volatility weighted portfolio.

Using a **rolling** volatility adjustment is important for two reasons:
1. it avoids the look-ahead bias that would exist if we calculated the volatility using the entire series, and
1. it dampens the time-varying volatility and volatility clustering in the returns (which you can see in the plot of returns above).

In this case, the volatility scaling doesn't have much dampening impact on the volatility clustering because of the length of the window (`r N` days). That's not particularly relevant for the purpose of this post though.

The R code for the volatility scaling is above. The call to the `rollapply()` function calculates the rolling `r N`-day standard deviation of the returns. Then `na.omit()` removes the first `r N-1` observations, since they are `NA` because there aren't enough observations to fill the `r N`-day window. Finally, we multiply by `r vol_scale` to scale the volatility to `r 100*vol_scale`%.

### Creating the trading signals

The trading signals are simple: go long (short) when today's price is above (below) the 100-day simple moving average. Dean's post calculates this signal in an unusual way (because that is how it's done in the post his analysis is based on): go long (short) when the average log return is above (below) zero.

It may not be obvious how and why this method works, so let me explain a bit. Remember that log returns are continuously compounded, so we sum them to calculate the total return (and the order they occur doesn't change the result).

For example, assume the price has increased over the last 100 days. That means the total return (i.e. sum of the log returns) for the period is positive. So the mean return is also positive, but smaller in absolute value (i.e. closer to zero). So the price at the end of the period is above the average price for the period and we should go long. You may have noticed that we can use the sign of the total return to calculate the signal, because dividing by the number of observations will not change the sign.

Important notes about this method:

* It only works for log returns because the total return is the sum of the individual returns and the order of the returns doesn't change the result.
* It only calculates the simple moving average. It doesn't work if you use unequal weight for any observation, because then the order of observations will affect the results.
* Due to the previous point, it creates different signals than if you take the difference between the price and the simple moving average of the original series. It calculates the signals on the *volatility-scaled* series. The volatility-scaled series gives different weight to each return based on the prior historical volatility.

The code to create the signals is below.

```{r, create-signals}
signal_long_only <- rollmean(scaled_returns, 100) > 0
signal_long_short <- sign(rollmean(scaled_returns, 100))

return_long_only  <- scaled_returns * signal_long_only
return_long_short <- scaled_returns * signal_long_short

portf_long_only  <- xts(rowSums(return_long_only)  / 3, index(return_long_only))
portf_long_short <- xts(rowSums(return_long_short) / 3, index(return_long_short))
```
